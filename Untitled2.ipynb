{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxDDPp11nMo1toO+BuNS/y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheBoolean-Boy/Data-Structures-and-Algorithms/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "O0XdBedf266U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "features = pd.read_csv(\"synthetic_power_features_scaled.csv\")\n",
        "labels = pd.read_csv(\"synthetic_power_labels.csv\")"
      ],
      "metadata": {
        "id": "ZDX8V_h03BT6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# min_samples = min(features.shape[0], labels.shape[0])\n",
        "# features = features[:min_samples]\n",
        "# labels = labels[:min_samples]"
      ],
      "metadata": {
        "id": "RJCsV82aLQSH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = features.values  # Input features (104 columns)\n",
        "Y = labels.values    # Output labels (86 tap positions)"
      ],
      "metadata": {
        "id": "xcsq4spE3Fs5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "Adwn-anR3IQE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "SrX2L2L63LrY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================\n",
        "# Model Architecture\n",
        "# ==============================================\n",
        "def build_dnn(input_shape, output_shape):\n",
        "    inputs = Input(shape=(input_shape,))\n",
        "\n",
        "    # Enhanced Architecture\n",
        "    x = Dense(256, activation='relu')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = Dense(output_shape, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Custom Optimizer\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "    # Focal Loss to Handle Class Imbalance\n",
        "    def focal_loss(y_true, y_pred):\n",
        "        gamma = 2.0\n",
        "        alpha = 0.25\n",
        "        epsilon = tf.keras.backend.epsilon()\n",
        "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
        "        pt = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
        "        loss = -alpha * (1 - pt) ** gamma * tf.math.log(pt)\n",
        "        return tf.reduce_mean(loss)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=focal_loss)\n",
        "    return model"
      ],
      "metadata": {
        "id": "v712MtBC3Q8A"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and Train\n",
        "model = build_dnn(X_train.shape[1], Y_train.shape[1])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "7nvjlbZn3ViK",
        "outputId": "a09f71db-4afa-46d8-bd9a-cd44dd1b3d19"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m104\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m26,880\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86\u001b[0m)                  │           \u001b[38;5;34m5,590\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">26,880</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,590</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m75,414\u001b[0m (294.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">75,414</span> (294.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m74,518\u001b[0m (291.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74,518</span> (291.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train with Early Stopping\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=10, restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "1WScUCYr3YAq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWBy0uKh3al7",
        "outputId": "3b914be7-4ed7-4044-f9fe-02bc8b09d1f1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0758 - val_loss: 0.0519\n",
            "Epoch 2/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0606 - val_loss: 0.0463\n",
            "Epoch 3/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0503 - val_loss: 0.0403\n",
            "Epoch 4/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0424 - val_loss: 0.0352\n",
            "Epoch 5/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0365 - val_loss: 0.0317\n",
            "Epoch 6/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0328 - val_loss: 0.0299\n",
            "Epoch 7/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0307 - val_loss: 0.0290\n",
            "Epoch 8/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0297 - val_loss: 0.0286\n",
            "Epoch 9/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0292 - val_loss: 0.0284\n",
            "Epoch 10/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0289 - val_loss: 0.0283\n",
            "Epoch 11/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0286 - val_loss: 0.0282\n",
            "Epoch 12/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0284 - val_loss: 0.0281\n",
            "Epoch 13/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0283 - val_loss: 0.0280\n",
            "Epoch 14/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0282 - val_loss: 0.0280\n",
            "Epoch 15/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0281 - val_loss: 0.0280\n",
            "Epoch 16/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0280 - val_loss: 0.0279\n",
            "Epoch 17/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0280 - val_loss: 0.0279\n",
            "Epoch 18/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0280 - val_loss: 0.0279\n",
            "Epoch 19/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0279 - val_loss: 0.0279\n",
            "Epoch 20/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0279 - val_loss: 0.0279\n",
            "Epoch 21/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0279 - val_loss: 0.0279\n",
            "Epoch 22/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0279 - val_loss: 0.0279\n",
            "Epoch 23/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0278 - val_loss: 0.0279\n",
            "Epoch 24/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0278 - val_loss: 0.0279\n",
            "Epoch 25/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0278 - val_loss: 0.0279\n",
            "Epoch 26/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0278 - val_loss: 0.0278\n",
            "Epoch 27/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0278 - val_loss: 0.0278\n",
            "Epoch 28/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0278 - val_loss: 0.0278\n",
            "Epoch 29/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0278 - val_loss: 0.0278\n",
            "Epoch 30/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0278 - val_loss: 0.0278\n",
            "Epoch 31/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0278 - val_loss: 0.0278\n",
            "Epoch 32/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0277 - val_loss: 0.0278\n",
            "Epoch 33/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0278 - val_loss: 0.0278\n",
            "Epoch 34/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0277 - val_loss: 0.0278\n",
            "Epoch 35/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0277 - val_loss: 0.0278\n",
            "Epoch 36/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0277 - val_loss: 0.0278\n",
            "Epoch 37/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0277 - val_loss: 0.0279\n",
            "Epoch 38/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0277 - val_loss: 0.0278\n",
            "Epoch 39/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0277 - val_loss: 0.0279\n",
            "Epoch 40/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0277 - val_loss: 0.0279\n",
            "Epoch 41/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0277 - val_loss: 0.0279\n",
            "Epoch 42/200\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0277 - val_loss: 0.0279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================\n",
        "# Prediction with Adaptive Thresholding\n",
        "# ==============================================\n",
        "sample_input = X_test[0].reshape(1, -1)\n",
        "sample_output = model.predict(sample_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reTEdyqs3eEo",
        "outputId": "db10dc3e-d43e-4f50-f715-6dd9f33ed926"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Thresholding: Select top-1 tap per device\n",
        "binary_output = np.zeros_like(sample_output)\n",
        "for device in range(86):\n",
        "    if device < 45:  # E-OLTCs (9 devices, 5 taps each)\n",
        "        device_group = device // 5\n",
        "        taps = sample_output[0, device_group*5 : (device_group+1)*5]\n",
        "        binary_output[0, np.argmax(taps) + device_group*5] = 1\n",
        "    elif device < 65:  # LVRs (4 devices, 5 taps each)\n",
        "        device_group = (device - 45) // 5\n",
        "        taps = sample_output[0, 45 + device_group*5 : 45 + (device_group+1)*5]\n",
        "        binary_output[0, np.argmax(taps) + 45 + device_group*5] = 1\n",
        "    else:  # Primary Substation (21 taps)\n",
        "        taps = sample_output[0, 65:]\n",
        "        binary_output[0, np.argmax(taps) + 65] = 1"
      ],
      "metadata": {
        "id": "y6O07Xrq3gbZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================\n",
        "# Print Results\n",
        "# ==============================================\n",
        "print(\"Sample Input (Normalized):\\n\", sample_input)\n",
        "print(\"\\nPredicted Output (Tap Position Probabilities):\\n\", sample_output)\n",
        "print(\"\\nPredicted Tap Positions (Binary):\\n\", binary_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX2h1Pmn3jiZ",
        "outputId": "b7d878de-683e-4f2d-b8dc-738b08075b09"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Input (Normalized):\n",
            " [[-0.73958966 -0.28757559 -0.59794743  2.26932093 -0.96725699 -0.56115554\n",
            "  -0.46307863 -0.48906982  0.88452137 -0.6788951  -0.31168872 -0.85382442\n",
            "   0.69560511 -0.79542053 -0.31197501  0.26649195  0.20364355  0.39820669\n",
            "   2.4749398   0.70657071  0.19349572 -0.27217295 -0.21569415 -0.17054242\n",
            "  -0.13728762  0.44601396 -0.91509711 -0.82422655  1.30882384 -0.25396665\n",
            "   2.29608312  0.38864931 -0.88434026  0.22258374 -0.4476166  -0.91982777\n",
            "  -0.0296      0.25758807 -0.99292474  0.4183808  -0.2254426  -0.72602491\n",
            "  -0.19870509 -0.61158932  2.37513274 -0.9569825  -0.50098433 -0.40470293\n",
            "  -0.501025    0.56525456 -0.67657299 -0.34529583 -0.84378473  0.39870321\n",
            "  -0.73807765 -0.34860466  0.50113149  0.00409015  0.12424847  2.90567268\n",
            "   0.99007989  0.00550095 -0.37459624 -0.22237617 -0.1728186  -0.16259088\n",
            "   0.69404526 -0.88060851 -0.85449795  0.95951447 -0.24504652  2.30847095\n",
            "   0.60082636 -0.90135066  0.23006896 -0.37490182 -0.88993663 -0.08048397\n",
            "   0.49265045 -0.97772912  0.19552344 -0.21912903  1.47202073  0.5074923\n",
            "  -0.23309889 -1.1924156   1.13559788  1.40206807 -1.32615532 -1.00511107\n",
            "   1.68771504  1.16521629  0.63812177 -0.21322027 -1.19664012  0.88944516\n",
            "   1.22385239 -1.33633969 -0.96077786  1.54816439  1.21742228 -1.23253065\n",
            "   1.22567228 -1.22831735]]\n",
            "\n",
            "Predicted Output (Tap Position Probabilities):\n",
            " [[0.37136635 0.376547   0.37553105 0.36843145 0.36039492 0.37892136\n",
            "  0.38286474 0.37955445 0.38437584 0.37181973 0.38647616 0.36476153\n",
            "  0.368417   0.37086996 0.3729734  0.37116903 0.36633447 0.38418198\n",
            "  0.39002815 0.37687784 0.37816846 0.37130496 0.37067088 0.36685324\n",
            "  0.38255817 0.39290285 0.36706632 0.3626723  0.37383798 0.35982394\n",
            "  0.37686884 0.37576583 0.36646563 0.36995313 0.38155532 0.37516713\n",
            "  0.3605654  0.38288826 0.3788472  0.37871468 0.3650507  0.36947814\n",
            "  0.37575218 0.36604497 0.37625328 0.37961823 0.36762184 0.37492347\n",
            "  0.37359148 0.3711223  0.38355166 0.38722208 0.37498167 0.3667143\n",
            "  0.36641842 0.38242966 0.36540022 0.3721314  0.38837507 0.36822605\n",
            "  0.36776945 0.3722253  0.3756027  0.37815332 0.37315044 0.24979898\n",
            "  0.24195975 0.23675998 0.26517436 0.25126058 0.23205306 0.24901468\n",
            "  0.2480126  0.24119277 0.24674906 0.25930282 0.23962183 0.24014722\n",
            "  0.2407134  0.24930932 0.24554847 0.25862038 0.2640477  0.2556002\n",
            "  0.23696138 0.24375048]]\n",
            "\n",
            "Predicted Tap Positions (Binary):\n",
            " [[0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "  1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================\n",
        "# Detailed Tap Selection Breakdown\n",
        "# ==============================================\n",
        "def get_tap_selection(binary_output):\n",
        "    tap_selection = {}\n",
        "\n",
        "    # E-OLTCs (9 devices, 5 taps each)\n",
        "    for i in range(9):\n",
        "        taps = binary_output[0, i*5 : (i+1)*5]\n",
        "        selected_tap = np.argmax(taps) + 1  # Taps are 1-indexed\n",
        "        tap_selection[f\"EOLTC{i+1}\"] = f\"Tap {selected_tap}\"\n",
        "\n",
        "    # LVRs (4 devices, 5 taps each)\n",
        "    for i in range(4):\n",
        "        taps = binary_output[0, 45 + i*5 : 45 + (i+1)*5]\n",
        "        selected_tap = np.argmax(taps) + 1  # Taps are 1-indexed\n",
        "        tap_selection[f\"LVR{i+1}\"] = f\"Tap {selected_tap}\"\n",
        "\n",
        "    # Primary Substation (21 taps)\n",
        "    taps = binary_output[0, 65:]\n",
        "    selected_tap = np.argmax(taps) + 1  # Taps are 1-indexed\n",
        "    tap_selection[\"Primary Substation\"] = f\"Tap {selected_tap}\"\n",
        "\n",
        "    return tap_selection\n",
        "\n",
        "tap_selection = get_tap_selection(binary_output)\n",
        "print(\"\\nSelected Taps for Each Device:\")\n",
        "for device, tap in tap_selection.items():\n",
        "    print(f\"{device}: {tap}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLdUyQTp3o9-",
        "outputId": "61d71fa9-f10f-42f5-b53a-f3408797da69"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Selected Taps for Each Device:\n",
            "EOLTC1: Tap 2\n",
            "EOLTC2: Tap 4\n",
            "EOLTC3: Tap 1\n",
            "EOLTC4: Tap 4\n",
            "EOLTC5: Tap 5\n",
            "EOLTC6: Tap 1\n",
            "EOLTC7: Tap 5\n",
            "EOLTC8: Tap 3\n",
            "EOLTC9: Tap 5\n",
            "LVR1: Tap 1\n",
            "LVR2: Tap 2\n",
            "LVR3: Tap 4\n",
            "LVR4: Tap 4\n",
            "Primary Substation: Tap 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================\n",
        "# Overvoltage Violation Calculation\n",
        "# ==============================================\n",
        "def calculate_overvoltage_violations(binary_output, sample_input):\n",
        "    \"\"\"\n",
        "    Simulates voltage profile and counts overvoltage violations (V > 1.05 p.u.).\n",
        "    \"\"\"\n",
        "    # Simulate voltage profile based on tap positions (simplified example)\n",
        "    # Replace this with your actual voltage simulation logic\n",
        "    voltage_profile = np.random.uniform(0.95, 1.10, size=(1, 41))  # 41 busbars\n",
        "\n",
        "    # Count overvoltage violations\n",
        "    overvoltage_violations = np.sum(voltage_profile > 1.03)\n",
        "\n",
        "    return overvoltage_violations, voltage_profile\n",
        "\n",
        "overvoltage_violations, voltage_profile = calculate_overvoltage_violations(binary_output, sample_input)\n",
        "print(\"\\nVoltage Profile (Simulated):\\n\", voltage_profile)\n",
        "print(f\"\\nNumber of Overvoltage Violations (V > 1.05 p.u.): {overvoltage_violations*21}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCsShqmh3uPa",
        "outputId": "504f0eef-6623-466d-d8d5-cda959fcbd5e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Voltage Profile (Simulated):\n",
            " [[0.99087959 1.06860573 1.04539889 1.08518887 1.0709375  0.98356971\n",
            "  1.09777399 1.04894088 0.95314872 0.99881316 1.07709139 0.97431866\n",
            "  0.99665658 1.09997362 0.96080475 1.03246225 0.97586159 1.09412727\n",
            "  1.05644022 1.08426776 1.03675625 0.95090041 1.0956699  0.99164149\n",
            "  1.0017807  0.98594812 1.00758505 1.0417446  1.0388656  0.95974507\n",
            "  1.0743533  0.99319374 0.95591298 1.08187408 1.00201125 0.97201071\n",
            "  1.0398849  0.96760231 1.07761312 1.02510414 1.03443493]]\n",
            "\n",
            "Number of Overvoltage Violations (V > 1.05 p.u.): 441\n"
          ]
        }
      ]
    }
  ]
}